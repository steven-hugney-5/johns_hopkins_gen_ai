{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB9H7BS_UH1E"
   },
   "source": [
    "# Aspect-Based Sentiment Classification Walkthrough\n",
    "\n",
    "In this notebook, we will explore the process of using LangChain with a large language model (LLM) for aspect-based sentiment classification (ABSC). ABSC is a granular approach to sentiment analysis that determines the sentiment (positive, negative, or neutral) toward specific aspects or attributes within a piece of text.\n",
    "\n",
    "For example, in the sentence:\n",
    "> \"The food at the restaurant was delicious, but the service was slow.\"\n",
    "\n",
    "The sentiment toward the aspect *\"food\"* is positive, while the sentiment toward the aspect *\"service\"* is negative.\n",
    "\n",
    "### Outline\n",
    "\n",
    "In this walkthrough, we will:\n",
    "\n",
    "1. **Load an ABSC Dataset:** Read in a dataset specifically designed for aspect-based sentiment classification. We will use the SemEval 2014 Dataset, which can be downloaded in  handy csv file from [Kaggle](https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis?select=Laptop_Train_v2.csv)\n",
    "2. **Build an LLM Using LangChain and HuggingFace:** Configure the large language model to handle sentiment classification tasks.\n",
    "3. **Craft a Labeling Prompt:** Create a well-structured prompt to guide the LLM in identifying sentiment for specific aspects of text.\n",
    "4. **Classify Dataset Examples:** Use the LLM and the prompt to classify examples in the dataset.\n",
    "5. **Evaluate Performance:** Measure classification accuracy using evaluation metrics such as precision, recall, and F1 score.\n",
    "\n",
    "### Example\n",
    "\n",
    "To understand ABSC better, let’s consider this example:\n",
    "\n",
    "```python\n",
    "review = \"The laptop's performance is outstanding, but the battery life is disappointing.\"\n",
    "aspects = [\"performance\", \"battery life\"]\n",
    "```\n",
    "\n",
    "The expected output is:\n",
    "\n",
    "| Aspect         | Sentiment   |\n",
    "|----------------|-------------|\n",
    "| Performance    | Positive    |\n",
    "| Battery Life   | Negative    |\n",
    "\n",
    "By the end of this notebook, you'll learn how to apply ABSC with LLMs to solve similar problems effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCM6JGuoUH1I"
   },
   "source": [
    "# Configure the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102171,
     "status": "ok",
     "timestamp": 1739975846893,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "6WOciQ0TUH1J",
    "outputId": "c61483ec-634b-426b-96e5-69d845815265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: langchain in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (0.4.34)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: transformers in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: langchain-huggingface in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-huggingface) (0.3.79)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-huggingface) (0.35.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.34)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: filelock in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install langchain\n",
    "! pip install transformers\n",
    "! pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXakdEC1UH1K"
   },
   "source": [
    "# Read in dataset and investigate the data\n",
    "\n",
    "Make sure to download the data from [Kaggle](https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis?select=Laptop_Train_v2.csv). We'll be working with the ```Laptop_Train_v2.csv```\n",
    "\n",
    "__Prompt__: I would like the python code to read in python dataframe from a csv named \"Laptop_Train_v2.csv\". I would like for you to downsample to 100 entries from the dataframe. Note that for the sampling, use the column 'id' to determine samples. So, there should be 100 unique values of 'id', but there will be more than 100 rows. I would like to also have the code to view the column names, a sample of the entries and summary of the values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1739975847615,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "ggfNSE7wUH1K",
    "outputId": "d131e281-7187-449e-d5a9-8b0efc064401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = \"Laptop_Train_v2.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "print(\"CSV file successfully loaded!\")\n",
    "\n",
    "# Downsample to 100 unique 'id' values\n",
    "sampled_ids = df['id'].drop_duplicates().sample(n=100)  # Randomly select 100 unique IDs\n",
    "df = df[df['id'].isin(sampled_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739975847639,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "qATnM8ZPUH1L",
    "outputId": "5e983eb9-9acd-4aa7-8b6a-ef47bd93acbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['id', 'Sentence', 'Aspect Term', 'polarity', 'from', 'to'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1739975847740,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "9x_4HdKxUH1L",
    "outputId": "9dc04c97-5cc6-486d-dd5c-c3c5bd76bd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Entries:\n",
      "      id                                           Sentence   Aspect Term  \\\n",
      "0   2339  I charge it at night and skip taking the cord ...          cord   \n",
      "1   2339  I charge it at night and skip taking the cord ...  battery life   \n",
      "34  2202  Pairing it with an iPhone is a pure pleasure -...       syncing   \n",
      "46   130  but now i have realized its a problem with thi...         brand   \n",
      "61   147                         The keyboard is too slick.      keyboard   \n",
      "\n",
      "    polarity  from  to  \n",
      "0    neutral    41  45  \n",
      "1   positive    74  86  \n",
      "34  positive    67  74  \n",
      "46  negative    48  53  \n",
      "61  negative     4  12  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the entries (first 5 rows by default)\n",
    "print(\"\\nSample Entries:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1739975847747,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "8V3l1PG8UH1L",
    "outputId": "7407e481-0b86-486a-e2e1-b4db6ece6455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Column Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154 entries, 0 to 2356\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           154 non-null    int64 \n",
      " 1   Sentence     154 non-null    object\n",
      " 2   Aspect Term  154 non-null    object\n",
      " 3   polarity     154 non-null    object\n",
      " 4   from         154 non-null    int64 \n",
      " 5   to           154 non-null    int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 8.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the values in each column\n",
    "print(\"\\nSummary of Column Values:\")\n",
    "print(df.info())  # Provides information about data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1739975847747,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "upcqdC7OUH1M",
    "outputId": "36a7033f-a4ac-4d51-bb8f-b9a5e02eec20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Summary:\n",
      "                 id                                           Sentence  \\\n",
      "count    154.000000                                                154   \n",
      "unique          NaN                                                100   \n",
      "top             NaN  Overall : Poor, Features: Average, Performance...   \n",
      "freq            NaN                                                  5   \n",
      "mean    1566.207792                                                NaN   \n",
      "std      904.833894                                                NaN   \n",
      "min        7.000000                                                NaN   \n",
      "25%      746.000000                                                NaN   \n",
      "50%     1609.500000                                                NaN   \n",
      "75%     2324.000000                                                NaN   \n",
      "max     3076.000000                                                NaN   \n",
      "\n",
      "         Aspect Term  polarity        from          to  \n",
      "count            154       154  154.000000  154.000000  \n",
      "unique           114         4         NaN         NaN  \n",
      "top     battery life  positive         NaN         NaN  \n",
      "freq               6        72         NaN         NaN  \n",
      "mean             NaN       NaN   48.525974   57.227273  \n",
      "std              NaN       NaN   43.781573   43.317421  \n",
      "min              NaN       NaN    0.000000    6.000000  \n",
      "25%              NaN       NaN   16.000000   28.000000  \n",
      "50%              NaN       NaN   38.000000   46.000000  \n",
      "75%              NaN       NaN   70.250000   79.750000  \n",
      "max              NaN       NaN  313.000000  318.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe(include='all'))  # Provides a statistical summary for all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg9Rozk0UH1M"
   },
   "source": [
    "__prompt__: Okay, now please give me the python code to look at the unique values, along with their counts of the \"polarity\" and the \"Aspect Term\" columns from the dataframe 'df'. You do not need to check for the columns or dataframe; they are already loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1739975847751,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "hfCVx0AmUH1M",
    "outputId": "4994e75f-db1d-49a8-8176-71d07371175a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values and their counts in the 'polarity' column:\n",
      "polarity\n",
      "positive    72\n",
      "negative    42\n",
      "neutral     34\n",
      "conflict     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values and their counts for \"polarity\"\n",
    "print(\"\\nUnique values and their counts in the 'polarity' column:\")\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1739975847856,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "RsizZCalUH1M",
    "outputId": "81961b42-cd45-4e43-838d-414797d400c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values and their counts in the 'Aspect Term' column:\n",
      "Aspect Term\n",
      "battery life     6\n",
      "price            6\n",
      "programs         6\n",
      "use              5\n",
      "works            4\n",
      "                ..\n",
      "boots up         1\n",
      "dependability    1\n",
      "look             1\n",
      "printer          1\n",
      "cord             1\n",
      "Name: count, Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values and their counts for \"Aspect Term\"\n",
    "print(\"\\nUnique values and their counts in the 'Aspect Term' column:\")\n",
    "print(df['Aspect Term'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEpbOaNYUH1M"
   },
   "source": [
    "# Instantiate a LLM for Classification\n",
    "\n",
    "__prompt__: Now, I need you to create an LLM object using LangChain. In particular, I would like to use the text-generation model of \"tiiuae/Falcon3-3B-Instruct\" from HuggingFace and use the 0th GPU. Make sure to import the langchain HuggingFace pipeline as \"from langchain_huggingface import HuggingFacePipeline\". Also, make sure when creating the pipeline to specify \"max_new_tokens = 500\", and make sure the pipeline only outputs the generated text and not the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338,
     "referenced_widgets": [
      "4cb236b211a84a57a9df9dc2b59ca915",
      "88a9ed5c779c44e39df501f8fab9984e",
      "fe57e5954cb9493f84b4842f810ec7b0",
      "280408967ec646ba9c9d765face6209d",
      "0b3713c2afd74a9fb23dfe153e33d9d0",
      "03a40de991a24cb5810ba52c82965df2",
      "6fabeba2bfe442e794cd32426cd0e70e",
      "c44de7799a4147798e608b587b6b966d",
      "d900cc81bc69430c8fad97c840cd29a8",
      "60ed0dd5a20a435792dcb26f759dd064",
      "9cd05ffce7ba48ed9713b8a7d0c66edf",
      "fa0c6fe5371e4b84b76ff74d8dcc0b3d",
      "066ad96fe8e04757bfaf439aa08b99dd",
      "7f498a16eb764401977885e20d88349d",
      "95b30256ab61473fafb41ae7b754bd1e",
      "5a0f25d243704573a23889f813f73908",
      "bb7356f4f28d4cc3acfef33112dbf604",
      "b88eddfcfc0249e5a02876e9db25dba3",
      "a746ae7230b245018c4433b3d509a896",
      "a2ecb84dc40c4962a9c2b88e25e6f30b",
      "841606ef0aa54d7a9ee8f1e0e6506ac0",
      "d6ecfcebe3df4689b44f4f28ec52b221",
      "fc7176fcc2e7413e84f8d9ce94273ddd",
      "7bfc3981288b451aa339fb6386d62c34",
      "a1ecc6d4cba34a89840a1aacdb8dddd8",
      "c8f4c01561ba4e47a35ef78348ab90b1",
      "45a3a00f6ca946c88b213f14bfab60b2",
      "592e69d898734d74ab1dbcccc7a9a11f",
      "622984569a3548629fd40740244bba2e",
      "6a797df0a0844e8cb6d04358a1ee17ba",
      "8ea03289b0c4482ba118d8b90b191643",
      "5b8d1f66063e468f8b7564a3e43dc9a7",
      "5290097e466f4d0fbfbd1ba8a697ed6d",
      "a5defcb1bad746208822be2d5eaca551",
      "904485f2c6be445b976642dedfa17191",
      "119d9d5686fa402f8c9b302a3d986d28",
      "74bab200d75c4b0d9c6b9225bb1e0d29",
      "d6e524297c794f019adfc97c2f6dcb89",
      "dd0e396baad74b32aee4e05c8de4ad32",
      "7cdcd3800bbb4d72b13eaf0f828b8d2e",
      "ca173a48b18a4126b767252f0a2aecb0",
      "be64c4a5424849ef8b2af663db39a45e",
      "e28434a1de6a48ddaeccaf1590748406",
      "36601d9fb7394e3e893114d195ad4730",
      "fa9c171a2310406eb5256d9fcf3f45a1",
      "e1f0f3ab916e4c099b9e143ab4739ed7",
      "5dfba9dbb0fa4edcb49e21d44614e77e",
      "df6cb4a6a9654a58ab2ca53975f19cb7",
      "797d0b7040d54cf790793ea1f4a3cfbf",
      "03af709f35044e69b3c3b1bf25e1e21c",
      "3a58ba2889fc44d5940cd44d94af26ee",
      "738228c6c1fb45a1a3cb8f43d9ecbcef",
      "01bf8028ff9248efad7933fb51b3baf3",
      "4045ba6f7fda488ab54b378a41a23f5e",
      "ef612e194fc54dd99fc5a465b25146bf",
      "6c7fce0ca53d44b9902cf6a5abfe7581",
      "9f689d078f13482280c1feb7822a1a12",
      "44a38777069d4e9e8d82ee8611d406b0",
      "71952ec84dbe46e38eaa446d98d74f6e",
      "e2cc8ca3212e492b8e890d4c22b41066",
      "c98d1c4cb71a494697cdf9c5565c00a4",
      "617260252b0b4dd09a36a5496ac59dfe",
      "2e5d81217ae74e39917ec20873a91648",
      "c96fa41a542e488da9ee8b9e3bed1476",
      "9c9c152afec34198a3f8dc57ad38e8f3",
      "1fc004033cbe41fb88e89cbb929043fc"
     ]
    },
    "id": "gK78ZmJXUH1M",
    "outputId": "274795f0-ee8a-4818-eb25-651194319025"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shugney20/Documents/genai/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 2 files: 100%|██████████| 2/2 [02:05<00:00, 62.75s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 18.18it/s]\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"tiiuae/Falcon3-3B-Instruct\"\n",
    "\n",
    "# Create a HuggingFace pipeline with the specified settings\n",
    "text_gen_pipeline = pipeline(\n",
    "    \"text-generation\",  # Specify the task\n",
    "    model=model_name,   # Specify the model\n",
    "    device=0,           # Use the 0th GPU\n",
    "    max_new_tokens=500, # Limit the number of generated tokens\n",
    "    return_full_text=False  # Ensure the output only includes the generated text\n",
    ")\n",
    "\n",
    "# Wrap the pipeline with LangChain's HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cUkUK_dVYfJ7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. \\n<|assistant|>\\nThis statement expresses a negative sentiment because it mentions that the speaker found the fan loud when it was running.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the sentiment of this staement: Also,kinda loud when the fan is running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGsejLRsUH1N"
   },
   "source": [
    "# Label the Aspects and Sentiments\n",
    "\n",
    "Now, we need to label the aspects and sentiments in the data. We first need to create an aspect sentiment labeling prompt\n",
    "\n",
    "__prompt__: I would like a prompt, formatted as a langchain prompt object, that does aspect-based sentiment classification of a laptop review. The prompt takes in a review of a laptop called {sentence} and does two things. First, it needs to determine what aspects are mentioned in the review. Examples include: 'screen', 'battery life', 'packaging', 'graphics', 'warranty', 'price', 'features'. Each review should have between 1 and 4 aspects, and aspects are usually only one or two word phrases from the review text that describe the laptop. Aspects are usually nouns, and not adverbs or adjectives like \"died\" or \"perfect\".\n",
    "\n",
    "Then for each aspect that is in the review - and only those aspects - it needs to provide the sentiment of the review towards that aspect. The possible sentiment values are \"positive\", \"negative\", \"neutral\", and \"conflict\". The prompt should also specify that the output should be of the form of a list of tuples, where the first entry in the tuple is the aspect, and second entry is the sentiment of the review towards that aspect. The prompt should also specify that the LLM should only output this list of tuples and no other words. So, as an example:\n",
    "\n",
    "sentence: \"The Macbook arrived in a nice twin packing and sealed in the box, all the functions works great.\"\n",
    "output: [('functions', 'positive'),('packaging', 'positive')]\n",
    "\n",
    "sentence: \"The USB port never worked\"\n",
    "output: [('USB port', 'negative')]\n",
    "\n",
    "sentence: \"The price and features more than met my needs.\"\n",
    "output: [('price', 'positive'), ('features', 'positive')]\n",
    "\n",
    "sentence: \"My warranty ran out right as the screen died.\"\n",
    "output: [('warranty', 'negative'), ('screen', 'negative')]\n",
    "\n",
    "sentence: \"The battery has standard life and the shipping was fast.\"\n",
    "output: [('battery', 'neutral'), ('shipping', 'positive')]\n",
    "\n",
    "sentence: \"Just a black screen!\"\n",
    "output: [('screen', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bniFGVJkUH1N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI that analyzes laptop reviews and determines the sentiment towards various aspects mentioned in the review.\n",
      "\n",
      "Given a review sentence, do the following:\n",
      "1. Identify the aspects mentioned in the review. Aspects are typically nouns, usually one or two words, and represent features of the laptop (such as 'screen', 'battery life', 'packaging', 'graphics', 'warranty', 'price', 'features'). There should be between 1 and 4 aspects mentioned in the review.\n",
      "2. For each identified aspect, determine the sentiment expressed in the review towards that aspect. The possible sentiments are 'positive', 'negative', 'neutral', or 'conflict'.\n",
      "3. Provide the output as a list of tuples, where the first entry in the tuple is the aspect, and the second entry is the sentiment towards that aspect.\n",
      "\n",
      "The output should only be the list of tuples with the aspects and sentiments and nothing else. Below are some examples:\n",
      "\n",
      "Example 1:\n",
      "Input: \"The Macbook arrived in a nice twin packing and sealed in the box, all the functions works great.\"\n",
      "Output: [('functions', 'positive'), ('packaging', 'positive')]\n",
      "\n",
      "Example 2:\n",
      "Input: \"The USB port never worked.\"\n",
      "Output: [('USB port', 'negative')]\n",
      "\n",
      "Example 3:\n",
      "Input: \"The price and features more than met my needs.\"\n",
      "Output: [('price', 'positive'), ('features', 'positive')]\n",
      "\n",
      "Example 4:\n",
      "Input: \"My warranty ran out right as the screen died.\"\n",
      "Output: [('warranty', 'negative'), ('screen', 'negative')]\n",
      "\n",
      "Example 5:\n",
      "Input: \"The battery has standard life and the shipping was fast.\"\n",
      "Output: [('battery', 'neutral'), ('shipping', 'positive')]\n",
      "\n",
      "Example 6:\n",
      "Input: \"Just a black screen!\"\n",
      "Output: [('screen', 'negative')]\n",
      "\n",
      "Input: \"The battery life was long, but the screen quality was disappointing.\"\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the template for aspect-based sentiment classification\n",
    "template = \"\"\"\n",
    "You are an AI that analyzes laptop reviews and determines the sentiment towards various aspects mentioned in the review.\n",
    "\n",
    "Given a review sentence, do the following:\n",
    "1. Identify the aspects mentioned in the review. Aspects are typically nouns, usually one or two words, and represent features of the laptop (such as 'screen', 'battery life', 'packaging', 'graphics', 'warranty', 'price', 'features'). There should be between 1 and 4 aspects mentioned in the review.\n",
    "2. For each identified aspect, determine the sentiment expressed in the review towards that aspect. The possible sentiments are 'positive', 'negative', 'neutral', or 'conflict'.\n",
    "3. Provide the output as a list of tuples, where the first entry in the tuple is the aspect, and the second entry is the sentiment towards that aspect.\n",
    "\n",
    "The output should only be the list of tuples with the aspects and sentiments and nothing else. Below are some examples:\n",
    "\n",
    "Example 1:\n",
    "Input: \"The Macbook arrived in a nice twin packing and sealed in the box, all the functions works great.\"\n",
    "Output: [('functions', 'positive'), ('packaging', 'positive')]\n",
    "\n",
    "Example 2:\n",
    "Input: \"The USB port never worked.\"\n",
    "Output: [('USB port', 'negative')]\n",
    "\n",
    "Example 3:\n",
    "Input: \"The price and features more than met my needs.\"\n",
    "Output: [('price', 'positive'), ('features', 'positive')]\n",
    "\n",
    "Example 4:\n",
    "Input: \"My warranty ran out right as the screen died.\"\n",
    "Output: [('warranty', 'negative'), ('screen', 'negative')]\n",
    "\n",
    "Example 5:\n",
    "Input: \"The battery has standard life and the shipping was fast.\"\n",
    "Output: [('battery', 'neutral'), ('shipping', 'positive')]\n",
    "\n",
    "Example 6:\n",
    "Input: \"Just a black screen!\"\n",
    "Output: [('screen', 'negative')]\n",
    "\n",
    "Input: \"{sentence}\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# Create the LangChain prompt object\n",
    "prompt = PromptTemplate(input_variables=[\"sentence\"], template=template)\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The battery life was long, but the screen quality was disappointing.\"\n",
    "formatted_prompt = prompt.format(sentence=sentence)\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3oNgaVhNUH1N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great battery, speed, display.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|assistant|>\\n[('battery', 'positive'), ('speed', 'positive'), ('display', 'positive')]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df.iloc[10,:]\n",
    "\n",
    "print(example['Sentence'])\n",
    "\n",
    "llm(prompt.format(sentence=example['Sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIoPXuIyUH1N"
   },
   "source": [
    "Now that we have our labeling prompt, lets construct our labeling chain.\n",
    "\n",
    "__prompt__: Now, given the LangChain prompt template \"prompt\", please give me the code to create a langchain chain using the pipe operator \"|\" with the prompt and an LLM called \"llm\". Please also create function to parse the output and remove extraneous output from the llm. Below are some examples:\n",
    "\n",
    "'\\n<|assistant|>\\n[output] \"[\\'hardware\\', \\'positive\\'], [\\'shipping\\', \\'negative\\']\"' -> [('hardware', 'positive'), ('shipping', 'negative')]\n",
    "\"<|assistant|>\\n['camera', 'neutral']\" -> [('camera', 'neutral')]\n",
    "\"<|assistant|>\\n[['graphics', 'positive']], \" -> [('graphics', 'positive')]\n",
    "\"<|assistant|>\\n[('touchpad', 'positive')]\" -> [('touchpad', 'positive')]\n",
    "\"<|assistant|>\\nsomething nonsensical, \" -> [('','')]\n",
    "\n",
    "The chain should resemble: label_prompt | llm | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aDxDFX64UH1N"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Function to parse the LLM output and remove extraneous content\n",
    "def parse_output(output: str):\n",
    "    try:\n",
    "        # Extract the list of tuples from the LLM output, which could be wrapped in extra characters\n",
    "        parsed_output = ast.literal_eval(output.strip().replace('<|assistant|>', '').strip())\n",
    "\n",
    "        # Ensure the output is a list of tuples\n",
    "        if isinstance(parsed_output, list) and all(isinstance(item, tuple) and len(item) == 2 for item in parsed_output):\n",
    "            return parsed_output\n",
    "        else:\n",
    "            return [('','')]  # Return an empty tuple if the output isn't valid\n",
    "    except Exception as e:\n",
    "        # Handle errors and return empty tuple in case of invalid format\n",
    "        print(f\"Error parsing output: {e}\")\n",
    "        return [('','')]\n",
    "\n",
    "# Define the LLM chain that uses the prompt and LLM\n",
    "chain = prompt | llm | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DCPMyRtfUH1N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great battery, speed, display.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('battery', 'positive'), ('speed', 'positive'), ('display', 'positive')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example['Sentence'])\n",
    "\n",
    "chain.invoke(example['Sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DUUxdiNUH1N"
   },
   "source": [
    "__prompt__: Now, produce code to iterate through the dataframe \"df\" and do the aspect-based sentiment classifications of the \"Sentence\" column of the dataframe. Please note that you only need to do a labeling for each unique entry in 'id' column. Store the output as a new dataframe called \"results_df\" with columns 'id' and \"aspect_sentiment\". Please also include tqdm to monitor performance into the labeling loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ytA4HViwUH1N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews:  57%|█████▋    | 57/100 [07:08<05:15,  7.35s/id]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing output: '[' was never closed (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews:  63%|██████▎   | 63/100 [08:12<06:56, 11.25s/id]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing output: '[' was never closed (<unknown>, line 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 100/100 [13:36<00:00,  8.17s/id]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id            aspect_sentiment\n",
      "0  2339  [(battery life, positive)]\n",
      "1  2202       [(syncing, positive)]\n",
      "2   130         [(brand, negative)]\n",
      "3   147      [(keyboard, negative)]\n",
      "4  1718                          []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "\n",
    "# Iterate through each unique 'id' in the DataFrame using tqdm to monitor progress\n",
    "for unique_id in tqdm(df['id'].drop_duplicates(), desc=\"Processing reviews\", unit=\"id\"):\n",
    "    # Get the first sentence for each unique 'id'\n",
    "    sentence = df[df['id'] == unique_id].iloc[0]['Sentence']\n",
    "\n",
    "    # Get the aspect-based sentiment output\n",
    "    aspect_sentiment = chain.invoke(sentence)\n",
    "\n",
    "    # Append the result to the results list\n",
    "    results.append({'id': unique_id, 'aspect_sentiment': aspect_sentiment})\n",
    "\n",
    "# Create the results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Show the first few rows of the results DataFrame\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHFLEVk1UH1O"
   },
   "source": [
    "# Evaluate the Results\n",
    "\n",
    "Now, we need to evaluate the results. One of the difficulties, however, is in the phrasing of the aspects. Its possible to have more than one term describe the same aspect, such as \"battery\" and \"battery life\" in \"the battery life is really good\". In both cases, we are talking about the \"battery\" but an exact match of the aspect words would fail. So, we will use the LLM to assist us in the evaluation of results by comparing entities and mathcing semantically close ones.\n",
    "\n",
    "First, we need to get out all of the aspect based sentiments from the original dataframe\n",
    "\n",
    "__prompt__ I would like the python code to get all of the aspects and their corresponding polarities from the dataframe 'df'. To do this, for each unique id in the column 'id' take out all of the entries from the 'Aspect Term' and 'polarity' columns and combine those into a tuple. Then combine all of the tuples for each unique id into a list. Then create a dataframe with columns 'id' and 'true_aspect_sentiment' from these values. So, for example, if the id '1111' has two entries, than there should be an entry in the new dataframe of {'id':1111, 'true_aspect_sentiment':[('aspect_1', 'sentiment_1'), ('aspect_2', 'sentiment_2')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzPoY6kDUH1O"
   },
   "outputs": [],
   "source": [
    "true_aspect_sentiment = []\n",
    "\n",
    "# Iterate through each unique 'id' in the DataFrame\n",
    "for unique_id in df['id'].drop_duplicates():\n",
    "    # Get the rows for the current unique 'id'\n",
    "    subset = df[df['id'] == unique_id]\n",
    "\n",
    "    # Create a list of tuples from the 'Aspect Term' and 'polarity' columns\n",
    "    aspect_sentiment_tuples = list(zip(subset['Aspect Term'], subset['polarity']))\n",
    "\n",
    "    # Append the result to the list, ensuring each entry has 'id' and 'true_aspect_sentiment'\n",
    "    true_aspect_sentiment.append({'id': unique_id, 'true_aspect_sentiment': aspect_sentiment_tuples})\n",
    "\n",
    "# Create the results DataFrame\n",
    "true_aspect_sentiment_df = pd.DataFrame(true_aspect_sentiment)\n",
    "\n",
    "# Show the first few rows of the results DataFrame\n",
    "print(true_aspect_sentiment_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlj138XhUH1O"
   },
   "source": [
    "__prompt__ now, please give me the code to join 'true_aspect_sentiment_df' with 'results_df' on the 'id' column. Call this dataframe 'eval_df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40Gn0WNvUH1O"
   },
   "outputs": [],
   "source": [
    "# Join 'true_aspect_sentiment_df' with 'results_df' on the 'id' column\n",
    "eval_df = pd.merge(true_aspect_sentiment_df, results_df, on='id', how='inner')\n",
    "\n",
    "# Show the first few rows of the resulting 'eval_df'\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv07huiZUH1O"
   },
   "source": [
    "Now, let's do the matching of the results, so that we can evaluate how we our LLM and prompt are doing.\n",
    "\n",
    "__prompt__ Please produce prompt to match tuples between two different lists in a langchain prompt template. The LLM will be given two lists of tuples, one called \"true aspect sentiments\" and one called \"predicted aspect sentiments\". The task is to determine for each tuple in the \"true aspect sentiments\" if there is a tuple in \"predicted aspect sentiments\" that closely matches. To do the matching, there are two steps. First, you need to determine if the first entry in the tuples are describing the same things. For example, \"battery\" and \"battery life\" are roughly describing the same things, while \"operating system\" and \"packaging\" are not. In other words, you must determine if the two first entries are semantically very close. Then, if the first entries of the tuples match, compare the second entries of the tuples for matching. The second entries are the sentiment terms and should match exactly. For example \"positive\" and \"positive\" match, but \"neutral\" and \"negative\" do not. Once you have match for a tuple, move to the next tuple; for each tuple in \"true aspect sentiments\", only count if it has at least one match. Finally, output the number of matches you have as a number (i.e., 0,1,2, etc.). Below are some examples to help you format this prompt for the LLM:\n",
    "\n",
    "Example 1:\n",
    "true aspect sentiments: [(suite of software, positive)]\n",
    "predicted aspect sentiments: [(software, positive), (suite, positive)]\n",
    "output: 1\n",
    "\n",
    "Example 2\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('extra space', 'positive'), ('keyboard', 'negative')]\n",
    "output: 2\n",
    "\n",
    "Example 3\n",
    "true aspect sentiments: [('price premium', 'negative'), ('features', 'positive')]\n",
    "predicted aspect sentiments: [('price', 'neutral'), ('features', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Example 4\n",
    "true aspect sentiments: [('web cam', 'neutral'), (\"burn cd's\", 'neutral')]\n",
    "predicted aspect sentiments: [('web cam', 'negative'), ('cd burning', 'negative')]\n",
    "output: 0\n",
    "\n",
    "Example 5\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('storage', 'positive'), ('screen', 'negative')]\n",
    "output: 1\n",
    "\n",
    "Example 6\n",
    "true aspect sentiments: [('battery life', 'positive')]\n",
    "predicted aspect sentiments: [('battery life', 'positive'), ('battery', 'positive')]\n",
    "output: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbHIccjJUH1O"
   },
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"true_aspect_sentiments\", \"predicted_aspect_sentiments\"],\n",
    "    template=\"\"\"\n",
    "You are given two lists of tuples. Each tuple consists of an aspect and a sentiment.\n",
    "Your task is to determine how many tuples in the predicted aspect sentiments list closely match tuples in the true aspect sentiments list.\n",
    "\n",
    "To match:\n",
    "1. First, you need to determine if the first entry (the aspect) in the tuples is describing the same thing. For example, \"battery\" and \"battery life\" are roughly describing the same thing, but \"operating system\" and \"packaging\" are not.\n",
    "2. If the first entries match, then check if the second entries (the sentiment values) are the same. For example, \"positive\" matches \"positive\", but \"positive\" does not match \"neutral\".\n",
    "3. Count each tuple in the true aspect sentiments list only if it has at least one match in the predicted aspect sentiments list.\n",
    "\n",
    "Please output the number of exact matches you find between the two lists. If no matches are found, output 0. Below are some examples:\n",
    "\n",
    "Example 1:\n",
    "true aspect sentiments: [(suite of software, positive)]\n",
    "predicted aspect sentiments: [(software, positive), (suite, positive)]\n",
    "output: 1\n",
    "\n",
    "Example 2:\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('extra space', 'positive'), ('keyboard', 'negative')]\n",
    "output: 2\n",
    "\n",
    "Example 3:\n",
    "true aspect sentiments: [('price premium', 'negative'), ('features', 'positive')]\n",
    "predicted aspect sentiments: [('price', 'neutral'), ('features', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Example 4:\n",
    "true aspect sentiments: [('web cam', 'neutral'), (\"burn cd's\", 'neutral')]\n",
    "predicted aspect sentiments: [('web cam', 'negative'), ('cd burning', 'negative')]\n",
    "output: 0\n",
    "\n",
    "Example 5:\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('storage', 'positive'), ('screen', 'negative')]\n",
    "output: 1\n",
    "\n",
    "Example 6:\n",
    "true aspect sentiments: [('battery life', 'positive')]\n",
    "predicted aspect sentiments: [('battery life', 'positive'), ('battery', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Here are the two lists:\n",
    "\n",
    "true aspect sentiments: {true_aspect_sentiments}\n",
    "predicted aspect sentiments: {predicted_aspect_sentiments}\n",
    "\n",
    "Your output should be the number of matching tuples. Do not provide any additional words or explanations.\n",
    "\n",
    "output:\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8mJwegpUH1O"
   },
   "source": [
    "__prompt__ now, please include the prompt object (which should be named \"eval_prompt\") into a langchain chain with the llm object \"llm\" using the \"|\" operator. Please aslo add a final function to the chain that parses the output into an integer format. So, the chain should look like\n",
    "\n",
    "eval_chain = eval_prompt | llm | number_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64ZBhFV9UH1O"
   },
   "outputs": [],
   "source": [
    "def number_parser(output: str) -> int:\n",
    "    try:\n",
    "        # Parse the number from the output, ensuring it's an integer\n",
    "        return int(output.strip())\n",
    "    except ValueError:\n",
    "        # In case the output is invalid, return 0 (or handle as needed)\n",
    "        return 0\n",
    "\n",
    "# Build the eval_chain with eval_prompt, llm, and number_parser\n",
    "eval_chain = eval_prompt | llm | number_parser\n",
    "\n",
    "# Example usage\n",
    "output = eval_chain.invoke({\n",
    "    \"true_aspect_sentiments\": [('price premium', 'negative'), ('features', 'positive')],\n",
    "    \"predicted_aspect_sentiments\": [('price', 'neutral'), ('features', 'positive')]\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_Vz79R5UH1O"
   },
   "source": [
    "__prompt__ Now, please give me the code to use the eval_chain on each entry in the eval_df. For the \"true_aspect_sentiments\" take the values from the \"true_aspect_sentiment\" column and for the \"predicted_aspect_sentiments\" take the values from the aspect_sentiment. Please save the outputs in a new column called \"matches\". Please also use tqdm when iterating over the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sYiPHBDUH1O"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# Create a function to apply eval_chain on each row of the dataframe\n",
    "def apply_eval_chain(row):\n",
    "    true_aspect_sentiments = row['true_aspect_sentiment']\n",
    "    predicted_aspect_sentiments = row['aspect_sentiment']\n",
    "\n",
    "    # Use the eval_chain to get the number of matches\n",
    "    return eval_chain.invoke({\n",
    "        \"true_aspect_sentiments\": true_aspect_sentiments,\n",
    "        \"predicted_aspect_sentiments\": predicted_aspect_sentiments\n",
    "    })\n",
    "\n",
    "eval_df['matches'] = eval_df.progress_apply(apply_eval_chain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORD1_-lkUH1O"
   },
   "outputs": [],
   "source": [
    "eval_df['matches'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBFKors7UH1P"
   },
   "source": [
    "__prompt__ Now, please give me the code to get the number of tuples in each list in the 'true_aspect_sentiment' column of \"eval_df\" and save that to the column \"num_true_aspects\". Also do the same for the 'aspect_sentiment' and call the column \"num_pred_aspects\". Finally, using the counts in the 'matches' column and the \"num_true_aspects\" compute the difference between them and divide this result by the value in \"num_true_aspects\", then subtract this vaue from 1.0, and take the min of this value an 1.0 (i.e., there should never be a result larger than 1.0). Then, save this result in a new column called \"accuracy\"\n",
    "\n",
    "Finally, give the code for computing the statistics from the \"accuracy\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J7m-B-tUH1P"
   },
   "outputs": [],
   "source": [
    "# Compute the number of tuples in each list in 'true_aspect_sentiment' and 'aspect_sentiment' columns\n",
    "eval_df['num_true_aspects'] = eval_df['true_aspect_sentiment'].apply(len)\n",
    "eval_df['num_pred_aspects'] = eval_df['aspect_sentiment'].apply(len)\n",
    "\n",
    "# Compute the accuracy based on the formula\n",
    "eval_df['accuracy'] = (\n",
    "    1.0 - ((eval_df['num_true_aspects'] - eval_df['matches']) / eval_df['num_true_aspects'])\n",
    ").clip(upper=1.0)  # Ensure accuracy does not exceed 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgjjlsLsUH1P"
   },
   "outputs": [],
   "source": [
    "# Compute basic statistics for the 'accuracy' column\n",
    "accuracy_stats = eval_df['accuracy'].describe()\n",
    "\n",
    "# Optionally, compute additional statistics like mean, median, etc.\n",
    "accuracy_mean = eval_df['accuracy'].mean()\n",
    "accuracy_median = eval_df['accuracy'].median()\n",
    "accuracy_std = eval_df['accuracy'].std()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Accuracy Statistics:\")\n",
    "print(accuracy_stats)\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f}\")\n",
    "print(f\"Median Accuracy: {accuracy_median:.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {accuracy_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wtH9KQLUH1P"
   },
   "source": [
    "__prompt__ finally, please give the python code to plot a histogram of the \"accuracy\" column of \"eval_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BZQ50RrUH1P"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of the 'accuracy' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(eval_df['accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Accuracy', fontsize=16)\n",
    "plt.xlabel('Accuracy', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwL6GeFtUH1P"
   },
   "source": [
    "__prompt__ What would be a good way to measure performance in this scenario? I have the number of correct matches in \"matches\", the number of aspect sentiments that should have been produced in \"num_true_aspects\" and the number of predicted aspects in \"num_pred_aspects\". Ideally, the number of correct matches should exactly match \"num_true_aspects\", and \"num_true_aspects\" should exactly match \"num_pred_aspects\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOz7TLNUUH1X"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate Precision, Recall, and F1 score\n",
    "precision = eval_df['matches'].sum() / eval_df['num_pred_aspects'].sum()\n",
    "recall = eval_df['matches'].sum() / eval_df['num_true_aspects'].sum()\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate Match Efficiency\n",
    "match_efficiency = 1.0 - abs(eval_df['num_pred_aspects'].sum() - eval_df['num_true_aspects'].sum()) / eval_df['num_true_aspects'].sum()\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Match Efficiency: {match_efficiency:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNfvO4koUH1Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bf8028ff9248efad7933fb51b3baf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "03a40de991a24cb5810ba52c82965df2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03af709f35044e69b3c3b1bf25e1e21c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066ad96fe8e04757bfaf439aa08b99dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb7356f4f28d4cc3acfef33112dbf604",
      "placeholder": "​",
      "style": "IPY_MODEL_b88eddfcfc0249e5a02876e9db25dba3",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "0b3713c2afd74a9fb23dfe153e33d9d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119d9d5686fa402f8c9b302a3d986d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca173a48b18a4126b767252f0a2aecb0",
      "max": 4989378032,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be64c4a5424849ef8b2af663db39a45e",
      "value": 4989378032
     }
    },
    "1fc004033cbe41fb88e89cbb929043fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "280408967ec646ba9c9d765face6209d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ed0dd5a20a435792dcb26f759dd064",
      "placeholder": "​",
      "style": "IPY_MODEL_9cd05ffce7ba48ed9713b8a7d0c66edf",
      "value": " 658/658 [00:00&lt;00:00, 68.5kB/s]"
     }
    },
    "2e5d81217ae74e39917ec20873a91648": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36601d9fb7394e3e893114d195ad4730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a58ba2889fc44d5940cd44d94af26ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4045ba6f7fda488ab54b378a41a23f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a38777069d4e9e8d82ee8611d406b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e5d81217ae74e39917ec20873a91648",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96fa41a542e488da9ee8b9e3bed1476",
      "value": 1
     }
    },
    "45a3a00f6ca946c88b213f14bfab60b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cb236b211a84a57a9df9dc2b59ca915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88a9ed5c779c44e39df501f8fab9984e",
       "IPY_MODEL_fe57e5954cb9493f84b4842f810ec7b0",
       "IPY_MODEL_280408967ec646ba9c9d765face6209d"
      ],
      "layout": "IPY_MODEL_0b3713c2afd74a9fb23dfe153e33d9d0"
     }
    },
    "5290097e466f4d0fbfbd1ba8a697ed6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "592e69d898734d74ab1dbcccc7a9a11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a0f25d243704573a23889f813f73908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8d1f66063e468f8b7564a3e43dc9a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dfba9dbb0fa4edcb49e21d44614e77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738228c6c1fb45a1a3cb8f43d9ecbcef",
      "max": 1465955608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01bf8028ff9248efad7933fb51b3baf3",
      "value": 1465955608
     }
    },
    "60ed0dd5a20a435792dcb26f759dd064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "617260252b0b4dd09a36a5496ac59dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "622984569a3548629fd40740244bba2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a797df0a0844e8cb6d04358a1ee17ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c7fce0ca53d44b9902cf6a5abfe7581": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f689d078f13482280c1feb7822a1a12",
       "IPY_MODEL_44a38777069d4e9e8d82ee8611d406b0",
       "IPY_MODEL_71952ec84dbe46e38eaa446d98d74f6e"
      ],
      "layout": "IPY_MODEL_e2cc8ca3212e492b8e890d4c22b41066"
     }
    },
    "6fabeba2bfe442e794cd32426cd0e70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71952ec84dbe46e38eaa446d98d74f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9c152afec34198a3f8dc57ad38e8f3",
      "placeholder": "​",
      "style": "IPY_MODEL_1fc004033cbe41fb88e89cbb929043fc",
      "value": " 1/2 [00:22&lt;00:22, 22.17s/it]"
     }
    },
    "738228c6c1fb45a1a3cb8f43d9ecbcef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74bab200d75c4b0d9c6b9225bb1e0d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e28434a1de6a48ddaeccaf1590748406",
      "placeholder": "​",
      "style": "IPY_MODEL_36601d9fb7394e3e893114d195ad4730",
      "value": " 4.99G/4.99G [01:58&lt;00:00, 42.2MB/s]"
     }
    },
    "797d0b7040d54cf790793ea1f4a3cfbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bfc3981288b451aa339fb6386d62c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_592e69d898734d74ab1dbcccc7a9a11f",
      "placeholder": "​",
      "style": "IPY_MODEL_622984569a3548629fd40740244bba2e",
      "value": "Downloading shards: 100%"
     }
    },
    "7cdcd3800bbb4d72b13eaf0f828b8d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f498a16eb764401977885e20d88349d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a746ae7230b245018c4433b3d509a896",
      "max": 16519,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2ecb84dc40c4962a9c2b88e25e6f30b",
      "value": 16519
     }
    },
    "841606ef0aa54d7a9ee8f1e0e6506ac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a9ed5c779c44e39df501f8fab9984e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03a40de991a24cb5810ba52c82965df2",
      "placeholder": "​",
      "style": "IPY_MODEL_6fabeba2bfe442e794cd32426cd0e70e",
      "value": "config.json: 100%"
     }
    },
    "8ea03289b0c4482ba118d8b90b191643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "904485f2c6be445b976642dedfa17191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd0e396baad74b32aee4e05c8de4ad32",
      "placeholder": "​",
      "style": "IPY_MODEL_7cdcd3800bbb4d72b13eaf0f828b8d2e",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "95b30256ab61473fafb41ae7b754bd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_841606ef0aa54d7a9ee8f1e0e6506ac0",
      "placeholder": "​",
      "style": "IPY_MODEL_d6ecfcebe3df4689b44f4f28ec52b221",
      "value": " 16.5k/16.5k [00:00&lt;00:00, 1.68MB/s]"
     }
    },
    "9c9c152afec34198a3f8dc57ad38e8f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd05ffce7ba48ed9713b8a7d0c66edf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f689d078f13482280c1feb7822a1a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c98d1c4cb71a494697cdf9c5565c00a4",
      "placeholder": "​",
      "style": "IPY_MODEL_617260252b0b4dd09a36a5496ac59dfe",
      "value": "Loading checkpoint shards:  50%"
     }
    },
    "a1ecc6d4cba34a89840a1aacdb8dddd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a797df0a0844e8cb6d04358a1ee17ba",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ea03289b0c4482ba118d8b90b191643",
      "value": 2
     }
    },
    "a2ecb84dc40c4962a9c2b88e25e6f30b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5defcb1bad746208822be2d5eaca551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_904485f2c6be445b976642dedfa17191",
       "IPY_MODEL_119d9d5686fa402f8c9b302a3d986d28",
       "IPY_MODEL_74bab200d75c4b0d9c6b9225bb1e0d29"
      ],
      "layout": "IPY_MODEL_d6e524297c794f019adfc97c2f6dcb89"
     }
    },
    "a746ae7230b245018c4433b3d509a896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b88eddfcfc0249e5a02876e9db25dba3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb7356f4f28d4cc3acfef33112dbf604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be64c4a5424849ef8b2af663db39a45e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c44de7799a4147798e608b587b6b966d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8f4c01561ba4e47a35ef78348ab90b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b8d1f66063e468f8b7564a3e43dc9a7",
      "placeholder": "​",
      "style": "IPY_MODEL_5290097e466f4d0fbfbd1ba8a697ed6d",
      "value": " 2/2 [02:34&lt;00:00, 69.63s/it]"
     }
    },
    "c96fa41a542e488da9ee8b9e3bed1476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c98d1c4cb71a494697cdf9c5565c00a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca173a48b18a4126b767252f0a2aecb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e524297c794f019adfc97c2f6dcb89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6ecfcebe3df4689b44f4f28ec52b221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d900cc81bc69430c8fad97c840cd29a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd0e396baad74b32aee4e05c8de4ad32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6cb4a6a9654a58ab2ca53975f19cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4045ba6f7fda488ab54b378a41a23f5e",
      "placeholder": "​",
      "style": "IPY_MODEL_ef612e194fc54dd99fc5a465b25146bf",
      "value": " 1.47G/1.47G [00:34&lt;00:00, 42.3MB/s]"
     }
    },
    "e1f0f3ab916e4c099b9e143ab4739ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03af709f35044e69b3c3b1bf25e1e21c",
      "placeholder": "​",
      "style": "IPY_MODEL_3a58ba2889fc44d5940cd44d94af26ee",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "e28434a1de6a48ddaeccaf1590748406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2cc8ca3212e492b8e890d4c22b41066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef612e194fc54dd99fc5a465b25146bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa0c6fe5371e4b84b76ff74d8dcc0b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_066ad96fe8e04757bfaf439aa08b99dd",
       "IPY_MODEL_7f498a16eb764401977885e20d88349d",
       "IPY_MODEL_95b30256ab61473fafb41ae7b754bd1e"
      ],
      "layout": "IPY_MODEL_5a0f25d243704573a23889f813f73908"
     }
    },
    "fa9c171a2310406eb5256d9fcf3f45a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1f0f3ab916e4c099b9e143ab4739ed7",
       "IPY_MODEL_5dfba9dbb0fa4edcb49e21d44614e77e",
       "IPY_MODEL_df6cb4a6a9654a58ab2ca53975f19cb7"
      ],
      "layout": "IPY_MODEL_797d0b7040d54cf790793ea1f4a3cfbf"
     }
    },
    "fc7176fcc2e7413e84f8d9ce94273ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bfc3981288b451aa339fb6386d62c34",
       "IPY_MODEL_a1ecc6d4cba34a89840a1aacdb8dddd8",
       "IPY_MODEL_c8f4c01561ba4e47a35ef78348ab90b1"
      ],
      "layout": "IPY_MODEL_45a3a00f6ca946c88b213f14bfab60b2"
     }
    },
    "fe57e5954cb9493f84b4842f810ec7b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c44de7799a4147798e608b587b6b966d",
      "max": 658,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d900cc81bc69430c8fad97c840cd29a8",
      "value": 658
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
